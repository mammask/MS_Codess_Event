mSet[1:4, rowMeans(x = .SD), by = id, .SDcols = newCols]
mSet[, Mean := rowMeans(x = .SD), by = id, .SDcols = newCols]
mSet
library(data.table)
library(microbenchmark)
mDim = 50000000
nLags = 5
mSet = data.table(id  = 1:mDim,
val = rnorm(mDim)
)
setkey(mSet, id)
newCols = c()
for (i in 1:nLags){
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet = mSet[complete.cases(mSet)]
mSet
mSet[, Mean := (var_lag1+var_lag2+var_lag3+var_lag4+var_lag5)/5]
mSet
mSet[, Mean := (val_lag1+val_lag2+val_lag3+val_lag4+val_lag5)/5]
mSet
mSet[, Mean := mean(c(val_lag1,val_lag2,val_lag3,val_lag4,val_lag5))]
mSet
mSet[, Median := median(c(val_lag1,val_lag2,val_lag3,val_lag4,val_lag5))]
mSet
mSet[, Mean := mean(c(val_lag1,val_lag2,val_lag3,val_lag4,val_lag5)), by = id]
mSet[, Median := median(c(val_lag1,val_lag2,val_lag3,val_lag4,val_lag5)), by = id]
install.packages("RcppRoll")
library(RcppRoll)
mSet[, RcppRoll::roll_median(x = val, n = 5)]
system.time(
mSet[, RollMean := RcppRoll::roll_mean(x = val, n = 5)]
)
system.time(
mSet[, RollMean := RcppRoll::roll_mean(x = val, n = 5, fill = NA)]
)
mSet
mSet
system.time(
mSet[, RollMean := RcppRoll::roll_mean(x = val, n = 5, fill = NA, align = "left")]
)
mSet
mSet
system.time(
mSet[, RollMean := RcppRoll::roll_mean(x = val, n = 5, fill = NA, align = "right")]
)
mSet
mSet
mSet[1:10]
mSet[1:10]
mSet[1:5, mean(val)]
system.time(
mSet[, RollMean := RcppRoll::roll_mean(x = val, n = 5, fill = NA, align = "right")]
mSet[, RollMean := RcppRoll::roll_median(x = val, n = 5, fill = NA, align = "right")]
)
library(data.table)
library(microbenchmark)
library(RcppRoll)
mDim = 50000000
nLags = 5
mSet = data.table(id  = 1:mDim,
val = rnorm(mDim)
)
setkey(mSet, id)
newCols = c()
system.time({
mSet[, RollMean := RcppRoll::roll_mean(x = val, n = 5, fill = NA, align = "right")]
mSet[, RollMedian := RcppRoll::roll_median(x = val, n = 5, fill = NA, align = "right")]
})
mSet
mSet
# Using manual implementation
newCols = c()
for (i in 1:nLags){
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
# Using manual implementation
system.time({
newCols = c()
for (i in 1:nLags){
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet[, Mean := sum(c(val_lag1,val_lag2,val_lag3,val_lag4,val_lag5))/nLags, by = id]
mSet[, newCols := NULL]
})
mSet
mSet
# Using manual implementation
system.time({
newCols = c()
for (i in 1:(nLags-1)}{
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4))/nLags, by = id]
mSet[, newCols := NULL]
})
library(data.table)
library(microbenchmark)
library(RcppRoll)
mDim = 50000000
nLags = 5
mSet = data.table(id  = 1:mDim,
val = rnorm(mDim)
)
setkey(mSet, id)
system.time({
mSet[, RollMean := RcppRoll::roll_mean(x = val, n = 5, fill = NA, align = "right")]
mSet[, RollMedian := RcppRoll::roll_median(x = val, n = 5, fill = NA, align = "right")]
})
# Using manual implementation
system.time({
newCols = c()
for (i in 1:(nLags-1)}{
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4))/nLags, by = id]
mSet[, newCols := NULL]
})
newCols = c()
for (i in 1:(nLags-1)}{
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4))/nLags, by = id]
newCols = c()
system.time
1:(nLags-1)
i=1
newCols = c(newCols,paste0("val_lag",i))
newCols
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
newCols = c()
for (i in 1:(nLags-1)}{
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4))/nLags, by = id]
newCols = c()
for (i in 1:(nLags-1){
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4))/nLags, by = id]
# Using manual implementation
system.time({
newCols = c()
for (i in 1:(nLags-1)){
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4))/nLags, by = id]
mSet[, newCols := NULL]
})
newCols = c()
for (i in 1:(nLags-1)){
newCols = c(newCols,paste0("val_lag",i))
mSet[, (paste0("val_lag",i)) := shift(x = val, n = i, fill = NA, type = "lag")]
}
mSet
mSet
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4))/nLags, by = id]
mSet[, Mean := (val + val_lag1+val_lag2+val_lag3+val_lag4)/nLags, by = id]
mSet
setwd("~/Repositories/TSWorkshop/R")
using<-function(...) {
libs<-unlist(list(...))
req<-unlist(lapply(libs,require,character.only=TRUE))
need<-libs[req==FALSE]
if(length(need)>0){
install.packages(need)
lapply(need,require,character.only=TRUE)
}
}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=8, fig.align = 'center')
# Load required libraries
source("R/load_lib.R")
use("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries")
# Load required libraries
source("R/load_lib.R")
use("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries")
using("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries")
www <- "http://www.massey.ac.nz/~pscowper/ts/global.dat"
fread(www)
Global = scan(www)
```{r fig1, fig.height = 5, fig.width = 8}
# Load required libraries
source("R/load_lib.R")
using("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries")
# Load data
dseries = fread("../data/DailyDelhiClimateTrain.csv",sep = ",")
# Access top 6 records
head(dseries)
# Access top 6 records
head(dseries)
# Convert to date format
dseries[, date := as.Date(date, format = "%Y-%m-%d")]
# Plot mean temperature
ggplot(data = dseries) + geom_line(aes(x = date, y = meantemp)) + xlab("Day") + ylab("Mean Temperature")
# Create summary statistics of the mean temperature series
dseries[, summary(meantemp)]
# Generate summary statistics by month
dseries[, .(`Min Mean Temperature` = min(meantemp),
`Max Mean Temperature` = max(meantemp),
`SD Mean Temperature` = sd(meantemp)
), by = month(date)]
# Create box plots per year
dseries[, month := month(date)]
ggplot(data = dseries) +
geom_boxplot(aes(x = factor(month(date)), y = meantemp)) +
xlab("Month") +
ylab("Mean Temperature") + facet_grid(~year(date))
using("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries","mathjaxr")
CBE
dseries
ggplot(data = dseries) + geom_line(aes(x = date, y = humidity)) + xlab("Day") + ylab("Mean Temperature")
# Convert to date format
dseries[, date := as.Date(date, format = "%Y-%m-%d")]
# Plot mean temperature
ggplot(data = dseries) + geom_line(aes(x = date, y = meantemp)) + xlab("Day") + ylab("Mean Temperature")
# Plot mean temperature
ggplot(data = dseries) + geom_line(aes(x = date, y = meantemp)) + xlab("Day") + ylab("Mean Temperature")
# Function to split the dataset into training validation and test set
train_valid_test_split <- function(x, trainSplit, validSplit, testSplit){
status <- rep(as.character(NA), times = length(x))
trainSize <- round(trainSplit * length(x))
validSize <- round(validSplit * length(x))
testSize  <- round(testSplit * length(x))
status[1:trainSize]                            <- "Train"
status[(trainSize+1):(trainSize+validSize)]    <- "Validation"
status[(trainSize+validSize+1):length(status)] <- "Test"
return(status)
}
# Split the dataset into training (0.6), validation (0.2) and test (0.2)
dseries[, Split := train_valid_test_split(date, 0.6, 0.2, 0.2)]
# Split the dataset into training (0.6), validation (0.2) and test (0.2)
dseries[, Split := train_valid_test_split(date, 0.6, 0.2, 0.2)]
### **Stationarity Tests**
# Convert mean temperature to time series object
dseries[, meantemp]
# Convert mean temperature to time series object
ts(dseries[, meantemp],frequency = 12, start = dseries[,min(date)])
# Convert mean temperature to time series object
tseries = ts(dseries[, meantemp],frequency = 12, start = dseries[,min(date)])
# Perform time series decomposition
autoplot(ecompose(tseries))
# Perform time series decomposition
autoplot(decompose(tseries))
# Load required libraries
source("R/load_lib.R")
using("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries")
# Load data
dseries = fread("../data/DailyDelhiClimateTrain.csv",sep = ",")
# Access top 6 records
head(dseries)
# Convert to date format
dseries[, date := as.Date(date, format = "%Y-%m-%d")]
# Plot mean temperature
ggplot(data = dseries) + geom_line(aes(x = date, y = meantemp)) + xlab("Day") + ylab("Mean Temperature")
# Create summary statistics of the mean temperature series
dseries[, summary(meantemp)]
# Generate summary statistics by month
dseries[, .(`Min Mean Temperature` = min(meantemp),
`Max Mean Temperature` = max(meantemp),
`SD Mean Temperature` = sd(meantemp)
), by = month(date)]
# Create box plots for each month
dseries[, month := month(date)]
ggplot(data = dseries) +
geom_boxplot(aes(x = factor(month(date)), y = meantemp)) +
xlab("Month") +
ylab("Mean Temperature")
# Create box plots per year
# dseries[, month := month(date)]
ggplot(data = dseries) +
geom_boxplot(aes(x = factor(month(date)), y = meantemp)) +
xlab("Month") +
ylab("Mean Temperature") + facet_grid(~year(date))
# Convert mean temperature to time series object
tseries = ts(dseries[, meantemp],frequency = 12, start = dseries[,min(date)])
# Perform time series decomposition
autoplot(decompose(tseries))
# Perform time series decomposition
autoplot(decompose(tseries, type = "additive"))
# Perform time series decomposition
autoplot(decompose(tseries, type = "additive")) +xlab("Date")
dseries[,min(date)]
dseries[,summary(date)]
dseries[,class(date)]
# Perform time series decomposition
autoplot(decompose(tseries, type = "additive")) +xlab("Date")
# Perform time series decomposition
autoplot(decompose(tseries, type = "multiplicative")) +xlab("Date")
# Perform time series decomposition
autoplot(decompose(tseries, type = "additive")) +xlab("Date")
autoplot(stl(tseries) +xlab("Date")
autoplot(stl(tseries)) +xlab("Date")
autoplot(stl(tseries,s.window="periodic", robust=TRUE)) +xlab("Date")
autoplot(stl(tseries,s.window="periodic", robust=TRUE)) +xlab("Date") + ggtitle("STL Decomposition") + xlab("Date")
# Check autocorrelation in time series
gridExtra::grid.arrange(
ggAcf(tseries) + ggtitle("Autocorrelation plot"),
ggPacf(tseries) + ggtitle("Partial autocorrelation plot")
)
train_data = copy(dseries[1:round(train_ratio*.N)])
# Obtain the training set only
train_ratio = 0.8
test_ratio  = 0.2
train_data = copy(dseries[1:round(train_ratio*.N)])
train_data
test_data  = copy(dseries[(round(train_ratio*.N)+1) : .N])
# Convert to time series object
tseries = ts(train_data[,meantemp], start  = train_data[,min(date)], frequency = 12)
# Decompose time series
decomp  = stl(tseries, s.window = "periodic")
# Plot decomposed time series using LOESS
autoplot(decomp)
kpss.test(x = tseries)
# Perfroming adf test
adf.test(x = tseries)
setwd("~/Repositories/MS_TS_Workshop/R")
setwd("~/Repositories/MS_TS_Workshop/R")
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=8, fig.align = 'center')
# Load required libraries
source("R/load_lib.R")
using("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries")
using("data.table", "ggplot2", "forecast","MLmetrics","gridExtra","tseries")
# Load data
dseries = fread("../data/DailyDelhiClimateTrain.csv",sep = ",")
# Access top 6 records
head(dseries)
# Convert to date format
dseries[, date := as.Date(date, format = "%Y-%m-%d")]
# Plot mean temperature
ggplot(data = dseries) + geom_line(aes(x = date, y = meantemp)) + xlab("Day") + ylab("Mean Temperature")
# Create summary statistics of the mean temperature series
dseries[, summary(meantemp)]
# Generate summary statistics by month
dseries[, .(`Min Mean Temperature` = min(meantemp),
`Max Mean Temperature` = max(meantemp),
`SD Mean Temperature` = sd(meantemp)
), by = month(date)]
# Create box plots for each month
dseries[, month := month(date)]
ggplot(data = dseries) +
geom_boxplot(aes(x = factor(month(date)), y = meantemp)) +
xlab("Month") +
ylab("Mean Temperature")
# Create box plots per year
# dseries[, month := month(date)]
ggplot(data = dseries) +
geom_boxplot(aes(x = factor(month(date)), y = meantemp)) +
xlab("Month") +
ylab("Mean Temperature") + facet_grid(~year(date))
# Convert mean temperature to time series object
tseries = ts(dseries[, meantemp],frequency = 12, start = dseries[,min(date)])
# Perform classical addive time series decomposition
autoplot(decompose(tseries, type = "additive")) +xlab("Date")
autoplot(stl(tseries,s.window="periodic", robust=TRUE)) +xlab("Date") + ggtitle("STL Decomposition") + xlab("Date")
# Check autocorrelation in time series
gridExtra::grid.arrange(
ggAcf(tseries) + ggtitle("Autocorrelation plot"),
ggPacf(tseries) + ggtitle("Partial autocorrelation plot")
)
# Obtain the training set only
train_ratio = 0.8
test_ratio  = 0.2
train_data = copy(dseries[1:round(train_ratio*.N)])
test_data  = copy(dseries[(round(train_ratio*.N)+1) : .N])
# Convert to time series object
tseries = ts(train_data[,meantemp], start  = train_data[,min(date)], frequency = 12)
# Decompose time series
decomp  = stl(tseries, s.window = "periodic")
# Plot decomposed time series using LOESS
autoplot(decomp)
# Plot decomposed time series using LOESS
autoplot(decomp)
### **Stationarity Tests**
Before fitting forecasting models, it is critical to check the stationarity of the time series. Two stationarity checks are described:
#### KPSS Test:
```{r}
kpss.test(x = tseries)
# Perfroming adf test
adf.test(x = tseries)
# Function to split the dataset into training validation and test set
train_valid_test_split <- function(x, trainSplit, validSplit, testSplit){
status <- rep(as.character(NA), times = length(x))
trainSize <- round(trainSplit * length(x))
validSize <- round(validSplit * length(x))
testSize  <- round(testSplit * length(x))
status[1:trainSize]                            <- "Train"
status[(trainSize+1):(trainSize+validSize)]    <- "Validation"
status[(trainSize+validSize+1):length(status)] <- "Test"
return(status)
}
# Split the dataset into training (0.6), validation (0.2) and test (0.2)
dseries[, Split := train_valid_test_split(date, 0.6, 0.2, 0.2)]
dseries
# Fit an auto arima in the training set
model = auto.arima(y = tseries, d = 0, max.p = 6, max.q = 6)
# Fit an auto arima in the training set
model = auto.arima(y = tseries, d = 0, max.p = 6, max.q = 6)
summary(model)
summary(model)
# Obtain fitted values
pred_train = model$fitted
# Obtain the mean temperature values in the training + the model predicted values in the training set
train_performance = copy(dseries[Split == "Train", .(date, meantemp)])
train_performance[, Predicted := pred_train]
# Fit an auto arima in the training set
model = auto.arima(y = tseries, d = 0, max.p = 6, max.q = 6)
# Fit an auto arima in the training set
model = auto.arima(y = tseries, d = 0, max.p = 6, max.q = 6)
summary(model)
# Obtain fitted values
pred_train = model$fitted
# Obtain the mean temperature values in the training + the model predicted values in the training set
train_performance = copy(dseries[Split == "Train", .(date, meantemp)])
pred_train
train_performance[, Predicted := pred_train]
# Convert to time series object
tseries = ts(dseries[Split == "Train",meantemp], start  = train_data[,min(date)], frequency = 12)
# Fit an auto arima in the training set
model = auto.arima(y = tseries, d = 0, max.p = 6, max.q = 6)
# Fit an auto arima in the training set
model = auto.arima(y = tseries, d = 0, max.p = 6, max.q = 6)
summary(model)
# Obtain fitted values
pred_train = model$fitted
# Obtain the mean temperature values in the training + the model predicted values in the training set
train_performance = copy(dseries[Split == "Train", .(date, meantemp)])
# Obtain the mean temperature values in the training + the model predicted values in the training set
train_performance = copy(dseries[Split == "Train", .(date, meantemp)])
train_performance[, Predicted := pred_train]
# Plot actual versus predicted series in the training set
ggplot(data = train_performance) +
geom_line(aes(x = date, y = meantemp)) +
geom_line(aes(x = date, y = Predicted), color = "red", linetype = "dashed") +
ggtitle("Actual versus Predicted Mean Temperature","Training set")
# Model performance in the training set
train_performance[, .(MAPE = MLmetrics::MAPE(y_pred = meantemp, y_true = Predicted),
R2 = MLmetrics::R2_Score(y_pred = meantemp, y_true = Predicted),
RMSE = MLmetrics::RMSE(y_pred = meantemp, y_true = Predicted)
)
]
# Perform walk forward validation in the validation set
stepsAhead = 1
dseries[, id := 1:.N]
# Define the start/ end point of walk forward validation
startingPoint = dseries[Split == "Validation", min(id)-stepsAhead]
endPoint = dseries[Split == "Validation", max(id)-stepsAhead]
# Loop over each time step
pred_valid = c()
for (i in startingPoint:endPoint){
# Get time series object
dseriesupd = dseries[1:i, ts(data = meantemp,
start = min(date),
frequency = 12
)
]
updatedModel = Arima(dseriesupd, model = model)
pred_valid = c(pred_valid,predict(updatedModel, n.ahead = stepsAhead)[["pred"]][[1]])
}
for (i in startingPoint:endPoint){
# Get time series object
dseriesupd = dseries[1:i, ts(data = meantemp,
start = min(date),
frequency = 12
)
]
updatedModel = Arima(dseriesupd, model = model)
pred_valid = c(pred_valid,predict(updatedModel, n.ahead = stepsAhead)[["pred"]][[1]])
}
# Obtain the mean temperature values in the training + the model predicted values in the training set
valid_performance = copy(dseries[Split == "Validation", .(date, meantemp)])
valid_performance[, Predicted := pred_valid]
length(pred_valid)
# Perform walk forward validation in the validation set
stepsAhead = 1
dseries[, id := 1:.N]
# Define the start/ end point of walk forward validation
startingPoint = dseries[Split == "Validation", min(id)-stepsAhead]
endPoint = dseries[Split == "Validation", max(id)-stepsAhead]
# Loop over each time step
pred_valid = c()
for (i in startingPoint:endPoint){
# Get time series object
dseriesupd = dseries[1:i, ts(data = meantemp,
start = min(date),
frequency = 12
)
]
updatedModel = Arima(dseriesupd, model = model)
pred_valid = c(pred_valid,predict(updatedModel, n.ahead = stepsAhead)[["pred"]][[1]])
}
# Obtain the mean temperature values in the training + the model predicted values in the training set
valid_performance = copy(dseries[Split == "Validation", .(date, meantemp)])
valid_performance[, Predicted := pred_valid]
# Plot actual versus predicted series in the training set
ggplot(data = valid_performance) +
geom_line(aes(x = date, y = meantemp)) +
geom_line(aes(x = date, y = Predicted), color = "red", linetype = "dashed") +
ggtitle("Actual versus Predicted Mean Temperature","Validation set")
valid_performance[, .(MAPE = MLmetrics::MAPE(y_pred = meantemp, y_true = Predicted),
R2 = MLmetrics::R2_Score(y_pred = meantemp, y_true = Predicted),
RMSE = MLmetrics::RMSE(y_pred = meantemp, y_true = Predicted)
)
]
